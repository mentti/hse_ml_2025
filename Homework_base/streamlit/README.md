
.md-файл с выводами о проделанной работе:
1. что было сделано (краткое описание каждого этапа);
2. какие результаты были получены (метрики + интерпретация);
3. что дало наибольший прирост качества;
4. что сделать не удалось и почему (это нормально и даже полезно);
5. оценка разработанного сервиса:
        - насколько приложение удобно в использовании;
        - что получилось визуализировать хорошо, а что — менее удачно;
        - какие ограничения или проблемы вы заметили;
        - какие улучшения планируете в следующей итерации.

1. В рамках домашней работы мы проработали базовый фреймворк анализа, обучения, интерпретации модели, а также вывели ее в веб-приложение. По порядку. 
    a) Мы сначала посмотрели базовые характеристики нашего датасета: какие строки и показатели там есть, где есть пропуски и дубли, определили какие данные надо обрабатывать. 
    б) Попробовали также сгенерировать отчет в ydata-profiling
    в) Избавились от лишних атрибутов, удалили дубли, заполнили пустоты. 
    г) Привели числовые признаки к нужному типу
    д) Посмотрели основные статистики, построили корреляции и графики распределения
    е) Подумали над взаимосвязями в данных
    ж) Попробовали обучить простую линейную регрессию на числовых атрибутах
    з) Оценили результаты обучения
    и) Скалировали атрибуты и повторили обучение
    к) Оценили результаты обучения
    л) Применили регуляризацию, но уже на модели Lasso и оценили результаты
    м) Подобрали параметры с помощью GridSearchCV для модели Lasso и оценили результаты
    н) Подобрали параметры с помощью GridSearchCV для модели ElasticNet и оценили результаты
    о) Обработали категориальные признаки с помощью One-Hot-Encoding и добавили их к обучению
    п) Подобрали параметры с помощью GridSearchCV для модели Ridge и оценили результаты
    р) Посчитали для наших моделей бизнес-метрику и оценили качество моделей
    с) Составил пайплан для формирования модели с обработкой для pickle
    т) Собраны файл с моделью
    у) Очень долго возились с написанием кода app.py для стримлит тестируя работу модели в приложении локально
    ф) Разместили модель и приложение в github, настроили отображение в веб
    х) Поправили ошибки
    ц) Написали строки выше

2. Обученные модели в рамках данного задания не совсем справляются со своей задачей, даже после всех улучшений качество предсказаний достаточно низкое. Модели без категориальных признаков по оценке R2 показывают результат в пределах 0.6, а с добавлением качественных атрибутов - 0.65. На многих наблюдениях модель дает сильные отклонения. Метрика accuracy(10%) менее 25% для всех обученных моделей.

3. Наибольший прирост качества произошел при добавлении категориальных признаков с помощью OHE.

4. Не хватило времени, чтобы поработать над корреляцией категориальных признаков, правильно обработать пустоты и не удалять torque. Также не хватило времени больше поработать с оптизацией модели, в частности, есть проблемы в отрицательных предсказаниях, что потребовало бы моделирования на логарифмической функции, да и в целом подробно и правильно составить пайплайн.

5. оценка разработанного сервиса:
    - насколько приложение удобно в использовании;
    Относительно удобно. Скорее всего, при получении дополнительного опыта с сервисом можно делать более удобные и красивые вещи.
    - что получилось визуализировать хорошо, а что — менее удачно;
    Да вроде все получилось. Конечно, хотелось бы лучше отображать корреляции.
    - какие ограничения или проблемы вы заметили;
    Очень много возни с реализацией самого приложения, а также ограниченный набор функциональностей
    - какие улучшения планируете в следующей итерации.
    Все, какие будут необходимы ))

